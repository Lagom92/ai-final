{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import model as ml\n",
    "import data\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from rouge import Rouge\n",
    "\n",
    "from configs import DEFINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Req. 1-5-1. bleu score 계산 함수\n",
    "def bleu_compute():\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Req. 1-5-2. rouge score 계산 함수\n",
    "def rouge_compute():\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Req. 1-5-3. main 함수 구성\n",
    "def main(self):\n",
    "    data_out_path = os.path.join(os.getcwd(), DATA_OUT_PATH)\n",
    "    os.makedirs(data_out_path, exist_ok=True)\n",
    "    # 데이터를 통한 사전 구성 한다.\n",
    "    char2idx, idx2char, vocabulary_length = data.load_voc()\n",
    "    # 훈련 데이터와 테스트 데이터를 가져온다.\n",
    "    train_q, train_a, test_q, test_a = None\n",
    "\n",
    "    # 훈련셋 인코딩 만드는 부분\n",
    "    train_input_enc = None\n",
    "    # 훈련셋 디코딩 입력 부분\n",
    "    train_input_dec = None\n",
    "    # 훈련셋 디코딩 출력 부분\n",
    "    train_target_dec = None\n",
    "\n",
    "    # 평가셋 인코딩 만드는 부분\n",
    "    eval_input_enc = None\n",
    "    # 평가셋 인코딩 만드는 부분\n",
    "    eval_input_dec = None\n",
    "    # 평가셋 인코딩 만드는 부분\n",
    "    eval_target_dec = None\n",
    "\n",
    "    # 현재 경로'./'에 현재 경로 하부에\n",
    "    # 체크 포인트를 저장한 디렉토리를 설정한다.\n",
    "    check_point_path = os.path.join(os.getcwd(), DEFINES.check_point_path)\n",
    "    # 디렉토리를 만드는 함수이며 두번째 인자 exist_ok가\n",
    "    # True이면 디렉토리가 이미 존재해도 OSError가\n",
    "    # 발생하지 않는다.\n",
    "    # exist_ok가 False이면 이미 존재하면\n",
    "    # OSError가 발생한다.\n",
    "    os.makedirs(check_point_path, exist_ok=True)\n",
    "\n",
    "    # 에스티메이터 구성한다.\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=ml.Model,  # 모델 등록한다.\n",
    "        model_dir=DEFINES.check_point_path,  # 체크포인트 위치 등록한다.\n",
    "        params={  # 모델 쪽으로 파라메터 전달한다.\n",
    "            'embedding_size': DEFINES.embedding_size,\n",
    "            'model_hidden_size': DEFINES.model_hidden_size,  # 가중치 크기 설정한다.\n",
    "            'ffn_hidden_size': DEFINES.ffn_hidden_size,\n",
    "            'attention_head_size': DEFINES.attention_head_size,\n",
    "            'learning_rate': DEFINES.learning_rate,  # 학습율 설정한다.\n",
    "            'vocabulary_length': vocabulary_length,  # 딕셔너리 크기를 설정한다.\n",
    "            'embedding_size': DEFINES.embedding_size,  # 임베딩 크기를 설정한다.\n",
    "            'layer_size': DEFINES.layer_size,\n",
    "            'max_sequence_length': DEFINES.max_sequence_length,\n",
    "            'xavier_initializer': DEFINES.xavier_initializer\n",
    "        })\n",
    "\n",
    "    # 학습 실행\n",
    "    classifier.train(input_fn=lambda: data.train_input_fn(\n",
    "        train_input_enc, train_input_dec, train_target_dec, DEFINES.batch_size), steps=DEFINES.train_steps)\n",
    "\n",
    "    eval_result = classifier.evaluate(input_fn=lambda: data.eval_input_fn(\n",
    "        eval_input_enc, eval_input_dec, eval_target_dec, DEFINES.batch_size))\n",
    "\n",
    "    print('\\nEVAL set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "\n",
    "    # 테스트용 데이터 만드는 부분이다.\n",
    "    # 인코딩 부분 만든다. 테스트용으로 [\"가끔 궁금해\"] 값을 넣어 형성된 대답과 비교를 한다.\n",
    "    predic_input_enc = None\n",
    "    # 학습 과정이 아니므로 디코딩 입력은\n",
    "    # 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
    "    predic_input_dec = None\n",
    "    # 학습 과정이 아니므로 디코딩 출력 부분도\n",
    "    # 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
    "    predic_target_dec = None\n",
    "\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=lambda: data.eval_input_fn(predic_input_enc, predic_input_dec, predic_target_dec, 1))\n",
    "\n",
    "    answer, finished = data.pred_next_string(predictions, idx2char)\n",
    "\n",
    "    # 예측한 값을 인지 할 수 있도록\n",
    "    # 텍스트로 변경하는 부분이다.\n",
    "    print(\"answer: \", answer)\n",
    "    print(\"Bleu score: \", bleu_compute(\"그 사람도 그럴 거예요.\", answer))\n",
    "    print(\"Rouge score: \", rouge_compute(\"그 사람도 그럴 거예요.\", answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
